{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15-transformer_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyqxg7uMszbWKXcDB8NFzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanSum/Happy-Sugar-Life-Weekly-Training/blob/master/15_transformer_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtM-b7eYtMwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as f\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsR3e2qMtlcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "nn_Softargmax = nn.Softmax   #fox wrong name"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmhBM8h0t_2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, p, d_input=None):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        #to-do: add more explanation on this part.\n",
        "        if d_input is None:\n",
        "            d_xq = d_xk = d_xv = d_model\n",
        "        else:\n",
        "            d_xq, d_xk, d_xv = d_input\n",
        "        \n",
        "        # Make sure that the embedding dimension of model is a multiple of number of heads\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.d_k = d_model // self.num_heads\n",
        "        \n",
        "        # There are tstill of dimension d_model. They will be split into number of heads\n",
        "        self.W_q = nn.Linear(d_xq, d_model, bias=False)\n",
        "        self.W_k = nn.Linear(d_xk, d_model, bias=False)\n",
        "        self.W_v = nn.Linear(d_xv, d_model, bias=False)\n",
        "\n",
        "        # Outputs of all sub-layers need to be of dimension d_model\n",
        "        self.W_h = nn.Linear(d_model, d_model)\n",
        "                             \n",
        "    def scaled_dot_product_attention(self, Q, K, V):\n",
        "      batch_size = Q.size(0)\n",
        "      k_length = K.size(-2)\n",
        "      \n",
        "      # Scaling by d_k so that the soft(arg)max doesn't saturate\n",
        "\n",
        "      # (bs, n_heads, q_length, dim_per_head)\n",
        "      # dim_per_head, I guess it is the self.d_k\n",
        "      Q = Q / np.sqrt(self.d_k)     \n",
        "\n",
        "\n",
        "      #K's size, I guess it is (bs, n_heads, dim_per_head, k_length)\n",
        "      # (bs, n_heads, q_length, k_length)\n",
        "      scores = torch.matmul(Q, K.transpose(2,3))\n",
        "      \n",
        "      A = nn_Softargmax(dim=-1)(scores)     #(bs, n_heads, q_length, k_length)\n",
        "\n",
        "      # Get the weighted average of the values\n",
        "      H = torch.matmul(A, V)                # (bs, n_heads, q_length, dim_per_head)\n",
        "\n",
        "      return H, A\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "      \"\"\"\n",
        "      Split the last dimension into (heads X depth)\n",
        "      Return after transpose to put in shape (batch_size X num_heads X seq+length X d_k)\n",
        "      \"\"\"\n",
        "      #I guess the reason why it is (batch_size, -1, self.num_heads, self.d_k).\n",
        "      #That is because it wants to seprate about number of heads in \n",
        "      #each sentence. And each sentense it has d_k for embedding.\n",
        "      return  x.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def group_heads(self, x, batch_size):\n",
        "      \"\"\"\n",
        "      Combine the heads again to get (batch_size X seq_length X num_heads X d_l)\n",
        "      \"\"\"\n",
        "      return x.transpose(1,2).contiguous().view(batch_size, -1,\n",
        "                                                self.num_heads * self.d_k\n",
        "                                                )\n",
        "    def forward(self, X_q, X_k, X_v):\n",
        "        batch_size, seq_length, dim = X_q.size()\n",
        "\n",
        "        # After transforming, split into num_heads\n",
        "        # Q: (bs, n_heads, q_length, dim_per_head)\n",
        "        # K: (bs, n_heads, k_length, dim_per_head)\n",
        "        # V: (bs, n_heads, v_length, dim_per_head)\n",
        "        Q = self.split_heads(self.W_q(X_q), batch_size)\n",
        "        K = self.split_heads(self.W_k(X_k), batch_size)\n",
        "        V = self.split_heads(self.W_v(X_v), batch_size)\n",
        "\n",
        "        # Calculate the attention weights for each of the heads\n",
        "        # to know how related they are\n",
        "        H_cat, A = self.scaled_dot_product_attention(Q, K, V)\n",
        "        \n",
        "        #Put all the heads back together by concat\n",
        "        # (bs, q_length, dim)\n",
        "        H_cat = self.group_heads(H_cat, batch_size)\n",
        "\n",
        "        # Final linear layer\n",
        "        H = self.W_h(H_cat)           # (bs, q_length, dim)\n",
        "\n",
        "        return H, A   "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwv32yKCR4a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8, p=0)\n",
        "def print_out(Q, K, V):\n",
        "    temp_out, temp_attn = temp_mha.scaled_dot_product_attention(Q, K, V)\n",
        "    print('Attention weights are:', temp_attn.squeeze())\n",
        "    print('Output is:', temp_out.squeeze())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxNKKK-ITpD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_K = torch.tensor(\n",
        "    [[10, 0, 0],\n",
        "     [0, 10, 0],\n",
        "     [0, 0, 10],\n",
        "     [0, 0, 10]]\n",
        ").float()[None, None]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i1p-OGyUe-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8636a7f-7710-40c1-9619-bdea0e16b9e5"
      },
      "source": [
        "test_K.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa4Wk0x-UGUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7502b633-0153-4a7f-b312-8a768c9c3bc8"
      },
      "source": [
        "test_V = torch.tensor(\n",
        "    [[    1,0,0],\n",
        "     [    10,0,0],\n",
        "     [    100,5,0],\n",
        "     [    1000,6,0]]\n",
        ").float()[None, None]\n",
        "test_Q = torch.tensor(\n",
        "    [[0, 10, 0]]\n",
        ").float()[None,None]\n",
        "print_out(test_Q, test_K, test_V)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are: tensor([3.7266e-06, 9.9999e-01, 3.7266e-06, 3.7266e-06])\n",
            "Output is: tensor([1.0004e+01, 4.0993e-05, 0.0000e+00])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr--OcDSY9v8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bc21fbba-d38e-49ed-b44d-818943f6adce"
      },
      "source": [
        "test_Q = torch.tensor(\n",
        "    [0, 0, 10]\n",
        ").float()[None,None]\n",
        "print_out(test_Q, test_K, test_V)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are: tensor([1.8633e-06, 1.8633e-06, 5.0000e-01, 5.0000e-01])\n",
            "Output is: tensor([549.9979,   5.5000,   0.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pQnk3tmW2Dl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "47fd3af1-dfd2-4ccd-9f65-cedaa84d578d"
      },
      "source": [
        "test_Q = torch.tensor(\n",
        "    [[0, 0, 10], [0, 10, 0],[10, 10, 0]]\n",
        ").float()[None,None]\n",
        "print_out(test_Q, test_K, test_V)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are: tensor([[1.8633e-06, 1.8633e-06, 5.0000e-01, 5.0000e-01],\n",
            "        [3.7266e-06, 9.9999e-01, 3.7266e-06, 3.7266e-06],\n",
            "        [5.0000e-01, 5.0000e-01, 1.8633e-06, 1.8633e-06]])\n",
            "Output is: tensor([[5.5000e+02, 5.5000e+00, 0.0000e+00],\n",
            "        [1.0004e+01, 4.0993e-05, 0.0000e+00],\n",
            "        [5.5020e+00, 2.0497e-05, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za2yGgu1aVml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d10172da-266e-4302-9ad9-4d10daea55ef"
      },
      "source": [
        "test_Q = torch.tensor(\n",
        "    [[0, 0, 10], [0, 10, 0], [10, 10, 0]]\n",
        ").float()[None,None]\n",
        "print_out(test_Q, test_K, test_V)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are: tensor([[1.8633e-06, 1.8633e-06, 5.0000e-01, 5.0000e-01],\n",
            "        [3.7266e-06, 9.9999e-01, 3.7266e-06, 3.7266e-06],\n",
            "        [5.0000e-01, 5.0000e-01, 1.8633e-06, 1.8633e-06]])\n",
            "Output is: tensor([[5.5000e+02, 5.5000e+00, 0.0000e+00],\n",
            "        [1.0004e+01, 4.0993e-05, 0.0000e+00],\n",
            "        [5.5020e+00, 2.0497e-05, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGzJArQyaSjQ",
        "colab_type": "text"
      },
      "source": [
        "We can see it will return two things.\n",
        "First is the index that it focus that is very similar from Q and K, index is given from the Attention argmax.\n",
        "In addition, the output is the average of the element in the value of that index or index(s). \n",
        "\n",
        "Average here is sum(element)/(number of index)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhtDh6sQY3AG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "075fe9b9-280e-4233-c7ce-af16f4943ea5"
      },
      "source": [
        "test_K = torch.tensor(\n",
        "    [[10, 0, 0],\n",
        "     [ 0,0, 10],\n",
        "     [ 0, 0,10],\n",
        "     [ 0, 0,10]]\n",
        ").float()[None,None]\n",
        "\n",
        "test_V = torch.tensor(\n",
        "    [[   1,0,0],\n",
        "     [  10,0,0],\n",
        "     [ 100,5,0],\n",
        "     [1000,6,0]]\n",
        ").float()[None,None]\n",
        "\n",
        "test_Q = torch.tensor(\n",
        "    [[0, 0, 10]]\n",
        ").float()[None,None]\n",
        "print_out(test_Q, test_K, test_V)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are: tensor([1.2422e-06, 3.3333e-01, 3.3333e-01, 3.3333e-01])\n",
            "Output is: tensor([369.9995,   3.6667,   0.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omrM9fz5dIbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, d_model, hidden_dim, p):\n",
        "        super().__init__()\n",
        "        self.k1convL1 = nn.Linear(d_model, hidden_dim)\n",
        "        self.k1convL2 = nn.Linear(hidden_dim, d_model)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.k1convL1(x)\n",
        "      x = self.activation(x)\n",
        "      x = self.k1convL2(x)\n",
        "      return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKkX0uvqeE0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, conv_hidden_dim, p = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads, p)\n",
        "        self.cnn = CNN(d_model, conv_hidden_dim, p)\n",
        "\n",
        "        self.layernorm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layernorm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "    def forward(self, x):\n",
        "\n",
        "      # Multi-head attention\n",
        "      attn_output, _ = self.mha(x, x, x)  #(batch_size, input_seq_len, d_model)\n",
        "\n",
        "      # Layer norm after adding the residual connection\n",
        "      out1 = self.layernorm1(x + attn_output)   #(batch_size, input seq_len, d_model)\n",
        "\n",
        "      #Feed forward\n",
        "      cnn_output = self.cnn(out1)   # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "      #Second layer norm after adding residual connection\n",
        "      out2 = self.layernorm2(out1 + cnn_output)   # (batch_size, input seq_len, d_model)\n",
        "      return out2\n",
        "    "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obg0-EHtoFgJ",
        "colab_type": "text"
      },
      "source": [
        "##Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV5SJ-uLoHHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_sinusoidal_embeddings(nb_p, dim, E):\n",
        "    theta = np.array([\n",
        "        [p / np.power(10000, 2* (j//2) / dim) for j in range(dim)]                      \n",
        "        for p in range(nb_p)\n",
        "    ])\n",
        "    E[:, 0::2] = torch.FloatTensor(np.sin(theta[:, 0::2]))\n",
        "    E[:, 1::2] = torch.FloatTensor(np.sin(theta[:, 1::2]))\n",
        "    E.detach_()\n",
        "    E.requires_grad = False\n",
        "    E = E.to(device)\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size, max_position_embeddings, p):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
        "        self.position_embeddings = nn.Embedding(max_position_embeddings, d_model)\n",
        "        create_sinusoidal_embeddings(\n",
        "            nb_p = max_position_embeddings,\n",
        "            dim = d_model,\n",
        "            E = self.position_embeddings.weight\n",
        "        )\n",
        "\n",
        "        self.LayerNorm = nn.LayerNorm(d_model, eps=1e-12)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        seq_length = input_ids.size(1)\n",
        "\n",
        "        # (max_seq_length)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
        "\n",
        "        # (bs, max, seq_length)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "\n",
        "        # Get word embeddings for each input id\n",
        "        #(bs, max_seq_length, dim)\n",
        "        word_embeddings = self.word_embeddings(input_ids)\n",
        "\n",
        "        # Get position embeddings for each position id\n",
        "        #(bs, max_seq_length, dim)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "         # Add them both \n",
        "        embeddings = word_embeddings + position_embeddings  # (bs, max_seq_length, dim)\n",
        "\n",
        "        # Layer norm\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        return embeddings\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fluwi0UB8EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, input_vocab_size, ff_hidden_dim,\n",
        "                 maximum_position_encoding, p = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embeddings(d_model, input_vocab_size, maximum_position_encoding, p)\n",
        "\n",
        "        self.enc_layers = nn.ModuleList()\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            self.enc_layers.append(EncoderLayer(d_model, num_heads, ff_hidden_dim, p))\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) # Transform to (batch_size, input_seq_length, d_model)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x)\n",
        "\n",
        "        return x # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QznNUxu5DwkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext.data as data\n",
        "import torchtext.datasets as datasets"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFoYKBceD17c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "febc2dca-8764-47ab-e77b-cb201b2412b8"
      },
      "source": [
        "max_len = 200\n",
        "text = data.Field(sequential=True, fix_length=max_len, batch_first=True, lower=True, dtype=torch.long)\n",
        "label = data.LabelField(sequential=False, dtype=torch.long)\n",
        "datasets.IMDB.download('./')\n",
        "ds_train, ds_test = datasets.IMDB.splits(text, label, path='./imdb/aclImdb/')\n",
        "print('train : ', len(ds_train))\n",
        "print('test : ', len(ds_test))\n",
        "print('train.fields :', ds_train.fields)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  25000\n",
            "test :  25000\n",
            "train.fields : {'text': <torchtext.data.field.Field object at 0x7f845f01ef28>, 'label': <torchtext.data.field.LabelField object at 0x7f845f01eeb8>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_OQ3qLZFsAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a2edf750-59d6-435c-a75a-471b8d915e4f"
      },
      "source": [
        "ds_train, ds_valid = ds_train.split(0.9)\n",
        "print('train : ',len(ds_train))\n",
        "print('valid : ',len(ds_valid))\n",
        "print('test : ',len(ds_test))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  22500\n",
            "valid :  2500\n",
            "test :  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ1iz-S-M004",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f7ed24f-8588-4417-f5fb-3c97e1419b6d"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD6HqipXNffx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31c88895-343f-4448-e099-8d4d7e0db16d"
      },
      "source": [
        "text.build_vocab"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Field.build_vocab of <torchtext.data.field.Field object at 0x7f845f01ef28>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VNjbAlcF3DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 50_000\n",
        "# text.build_vocab(ds_train, max_size=num_words, specials=['<pad>','<unk>'])\n",
        "text.build_vocab(ds_train, max_size=num_words)\n",
        "label.build_vocab(ds_train)\n",
        "vocab = text.vocab"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J65jk5jOHYNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 164\n",
        "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
        "    (ds_train, ds_valid, ds_test), batch_size = batch_size, sort_key = lambda x: len(x.text), repeat=False)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTJydIo_IUWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, conv_hidden_dim, input_vocab_size, num_answers):\n",
        "      super().__init__()\n",
        "\n",
        "      self.encoder = Encoder(num_layers, d_model, num_heads, conv_hidden_dim, input_vocab_size,\n",
        "                       maximum_position_encoding=10000)\n",
        "      self.dense = nn.Linear(d_model, num_answers)       #this one must be the output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "\n",
        "        x, _ = torch.max(x, dim=1)\n",
        "        x    =     self.dense(x)\n",
        "        return x"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUJs27QvKIkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "72ee6b41-6c32-4ff5-875f-f48df7c51890"
      },
      "source": [
        "model = TransformerClassifier(num_layers=1, d_model=32, num_heads=2, \n",
        "                         conv_hidden_dim=128, input_vocab_size=50002, num_answers=2)\n",
        "model.to(device)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-ba327e1a5694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = TransformerClassifier(num_layers=1, d_model=32, num_heads=2, \n\u001b[0;32m----> 2\u001b[0;31m                          conv_hidden_dim=128, input_vocab_size=50002, num_answers=2)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-133-85651d41740b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_layers, d_model, num_heads, conv_hidden_dim, input_vocab_size, num_answers)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       self.encoder = Encoder(num_layers, d_model, num_heads, conv_hidden_dim, input_vocab_size,\n\u001b[0;32m----> 6\u001b[0;31m                        maximum_position_encoding=10000)\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_answers\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m#this one must be the output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-279d3ff55a58>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_layers, d_model, num_heads, input_vocab_size, ff_hidden_dim, maximum_position_encoding, p)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_position_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-124-2accf712718e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, vocab_size, max_position_embeddings, p)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mnb_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_position_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-124-2accf712718e>\u001b[0m in \u001b[0;36mcreate_sinusoidal_embeddings\u001b[0;34m(nb_p, dim, E)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh049h2MbTvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "130aa04e-5863-48bd-e2fb-c578f02926ac"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep  8 20:41:06 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    39W / 300W |   1267MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJerBQb_WS8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsOB3f29LI9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "epochs = 10\n",
        "t_total = len(train_loader) * epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOgxDd0uV-IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u9Lb7Q2Wfbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, valid_loader):\n",
        "    for epoch in range(epochs):\n",
        "        train_iterator, valid_iterator = iter(train_loader), iter(valid_loader)\n",
        "        nb_batches_train = len(train_loader)\n",
        "        train_acc = 0\n",
        "        model.train()\n",
        "        losses = 0.0\n",
        "\n",
        "        for batch in train_iterator:\n",
        "            x = batch.text.to(device)\n",
        "            y = batch.label.to(device)\n",
        "\n",
        "            out = model(x)  # step 1\n",
        "\n",
        "            loss = f.cross_entropy(out, y)  # step 2\n",
        "\n",
        "            model.zero_grad()  # step3\n",
        "\n",
        "            loss.backward()  # step 4\n",
        "            loss += loss.item()\n",
        "\n",
        "            optimizer.step  # step 5\n",
        "\n",
        "            train_ac += (out.argmax(1) == y).cpu().numpy().mean()\n",
        "\n",
        "        print(f\"Train loss at epoch {epoch} is {losses / nb_batches_train}\")\n",
        "        print(f\"Train accuracy: {train_acc / nb_batches_train}\")\n",
        "        print(f\"Evaluating on validation:\")\n",
        "        evaluate(valid_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF67S739X0nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(data_loader):\n",
        "    data_iterator = iter(data_loader)\n",
        "    nb_batches = len(data_loader)\n",
        "    model.eval\n",
        "    acc = 0\n",
        "    for batch in data_iterator:\n",
        "        x = batch.text.to(device)\n",
        "        y = batch.text.to(device)\n",
        "\n",
        "        out = model(x)\n",
        "        acc += (out.argmax(1) == y).cpu().numpy().mean()\n",
        "    print(f\"Eval accuracy: {acc / nb_batches}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiM-49f7YcUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(train_loader, valid_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyyGgZ-6ZO10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRTh-dABYgQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}